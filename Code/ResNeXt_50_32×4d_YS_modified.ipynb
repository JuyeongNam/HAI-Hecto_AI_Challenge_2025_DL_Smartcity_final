{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ4CvPfe-wVt"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj1ekGo2-wVv",
        "outputId": "7d08bdc4-f6e5-4d6a-f5f5-7c95f94459d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngHYZAUj-wVw"
      },
      "source": [
        "# Hyperparameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kHcdD9pY-wVw"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'IMG_SIZE': 224,\n",
        "    'BATCH_SIZE': 32,\n",
        "    'EPOCHS': 10,\n",
        "    'LEARNING_RATE': 1e-4,\n",
        "    'SEED' : 42\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A199kyt-wVx"
      },
      "source": [
        "# Fixed RandomSeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uBWk8pfN-wVx"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED']) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVxi3qqe-wVy"
      },
      "source": [
        "# CustomDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sKcwnNZJ-wVy"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_test=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.samples = []\n",
        "\n",
        "        if is_test:\n",
        "            for fname in sorted(os.listdir(root_dir)):\n",
        "                if fname.lower().endswith(('.jpg')):\n",
        "                    img_path = os.path.join(root_dir, fname)\n",
        "                    self.samples.append((img_path,))\n",
        "        else:\n",
        "            self.classes = sorted(os.listdir(root_dir))\n",
        "            self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "            for cls_name in self.classes:\n",
        "                cls_folder = os.path.join(root_dir, cls_name)\n",
        "                for fname in os.listdir(cls_folder):\n",
        "                    if fname.lower().endswith(('.jpg')):\n",
        "                        img_path = os.path.join(cls_folder, fname)\n",
        "                        label = self.class_to_idx[cls_name]\n",
        "                        self.samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            img_path = self.samples[idx][0]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image\n",
        "        else:\n",
        "            img_path, label = self.samples[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR1gZtb7-wVz"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y504gbRu13du",
        "outputId": "2c2ea94f-a042-4730-f9f4-06a656cdbe5a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vUqjEvp4-wVz"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/SmartCityDeeplearning')\n",
        "train_root = './train'\n",
        "test_root = './test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-VB1RVd6-wVz"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fgFhGWqqv_A_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fb7900-7937-4f41-dd33-e0382080a503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 이미지 수: 3106\n",
            "train 이미지 수: 2484, valid 이미지 수: 622\n"
          ]
        }
      ],
      "source": [
        "# 전체 데이터셋 로드\n",
        "full_dataset = CustomImageDataset(train_root, transform=None)\n",
        "print(f\"총 이미지 수: {len(full_dataset)}\")\n",
        "\n",
        "targets = [label for _, label in full_dataset.samples]\n",
        "class_names = full_dataset.classes\n",
        "\n",
        "# Stratified Split\n",
        "train_idx, val_idx = train_test_split(\n",
        "    range(len(targets)), test_size=0.2, stratify=targets, random_state=42\n",
        ")\n",
        "\n",
        "# Subset + transform 각각 적용\n",
        "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform), train_idx)\n",
        "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform), val_idx)\n",
        "print(f'train 이미지 수: {len(train_dataset)}, valid 이미지 수: {len(val_dataset)}')\n",
        "\n",
        "\n",
        "# DataLoader 정의\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLCUlesy-wV0"
      },
      "source": [
        "# Model Define"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1i0Isb9F-wV0"
      },
      "outputs": [],
      "source": [
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.backbone = models.resnext50_32x4d(pretrained=True)\n",
        "        self.feature_dim = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Identity()  # feature extractor로만 사용\n",
        "        self.head = nn.Linear(self.feature_dim, num_classes)  # 분류기\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-o5QZfjD-wV0"
      },
      "source": [
        "# Train/ Validation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ],
      "metadata": {
        "id": "DvR0Xy4vDOuX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BaseModel(num_classes=len(class_names)).to(device)\n",
        "best_logloss = float('inf')\n",
        "\n",
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 옵티마이저\n",
        "optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
        "\n",
        "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
        "\n",
        "# 학습 및 검증 루프\n",
        "for epoch in range(CFG['EPOCHS']):\n",
        "    # Train\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)  # logits\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch+1}/{CFG['EPOCHS']}] Validation\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Accuracy\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # LogLoss\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
        "\n",
        "    # 결과 출력\n",
        "    print(f\"Train Loss : {avg_train_loss:.4f} || Valid Loss : {avg_val_loss:.4f} | Valid Accuracy : {val_accuracy:.4f}%\")\n",
        "\n",
        "    # Best model 저장\n",
        "    if val_logloss < best_logloss:\n",
        "        best_logloss = val_logloss\n",
        "        torch.save(model.state_dict(), f'best_model.pth')\n",
        "        print(f\"📦 Best model saved at epoch {epoch+1} (logloss: {val_logloss:.4f})\")\n",
        "\n",
        "    early_stopping(avg_val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"⛔ Early stopping triggered.\")\n",
        "        break"
      ],
      "metadata": {
        "id": "yV8r2ysfEO7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}