{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OdM98q3YTu9q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vit_l_16, ViT_L_16_Weights\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GPU_NUM = 1\n",
        "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.set_device(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Config**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h_z37-sCVW_6"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    \"IMG_SIZE\": 224,\n",
        "    \"NUM_CLASSES\": 396,\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"EPOCHS\": 500,\n",
        "    \"LR\": 1e-4,\n",
        "    \"WEIGHT_DECAY\": 1e-2,\n",
        "    \"PATIENCE\": 5,\n",
        "    \"SEED\": 42,\n",
        "    # AMP & Grad‑clip\n",
        "    \"USE_AMP\": False,\n",
        "    \"GRAD_CLIP\": 1.0,\n",
        "}\n",
        "\n",
        "BASE_DIR = Path(r\"D:/dacon_HAI\")\n",
        "PATHS = {\n",
        "    \"BASE\": BASE_DIR,\n",
        "    \"TRAIN\": BASE_DIR / \"open\" / \"train\",\n",
        "    \"TEST\":  BASE_DIR / \"open\" / \"test\",\n",
        "    \"CKPT\":  BASE_DIR / \"checkpoints\",\n",
        "    \"LOG\":   BASE_DIR / \"logs\",\n",
        "    \"SUBMIT\": BASE_DIR / \"submission\",\n",
        "}\n",
        "for p in PATHS.values():\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Normalization stats ---\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FXjhJninT2py"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "seed_everything(CFG[\"SEED\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdr2jbS-Oixh"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_test=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.samples = []\n",
        "\n",
        "        if self.is_test:\n",
        "            for fname in sorted(os.listdir(root_dir)):\n",
        "                if fname.lower().endswith('.jpg'):\n",
        "                    img_path = os.path.join(root_dir, fname)\n",
        "                    self.samples.append((img_path,))\n",
        "        else:\n",
        "            self.classes = sorted(os.listdir(root_dir))\n",
        "            self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "            for cls_name in self.classes:\n",
        "                cls_folder = os.path.join(root_dir, cls_name)\n",
        "                for fname in os.listdir(cls_folder):\n",
        "                    if fname.lower().endswith('.jpg'):\n",
        "                        img_path = os.path.join(cls_folder, fname)\n",
        "                        label = self.class_to_idx[cls_name]\n",
        "                        self.samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            img_path = self.samples[idx][0]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, os.path.basename(img_path)\n",
        "        else:\n",
        "            img_path, label = self.samples[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "\n",
        "spatial_aug = transforms.RandomChoice([\n",
        "    transforms.RandomResizedCrop(CFG[\"IMG_SIZE\"], scale=(0.8, 1.0)),\n",
        "    transforms.CenterCrop(CFG[\"IMG_SIZE\"]),\n",
        "])\n",
        "geom_aug = transforms.RandomChoice([\n",
        "    transforms.RandomHorizontalFlip(p=1.0),\n",
        "    transforms.RandomVerticalFlip(p=1.0),\n",
        "    transforms.RandomRotation(degrees=(-30, 30), interpolation=transforms.InterpolationMode.BILINEAR, fill=0),\n",
        "])\n",
        "pixel_aug = transforms.RandomChoice([\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 5.0)),\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
        "])\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n",
        "    transforms.RandomApply([spatial_aug], p=0.5),\n",
        "    transforms.RandomApply([geom_aug],    p=0.5),\n",
        "    transforms.RandomApply([pixel_aug],   p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKc8X1W9UL1d",
        "outputId": "910f38aa-c1fd-4b4d-dcb5-5604176242e0"
      },
      "outputs": [],
      "source": [
        "full_ds = CustomImageDataset(PATHS[\"TRAIN\"], transform=train_tf, is_test=False)\n",
        "print(f\"Full data: {len(full_ds):,}\")\n",
        "\n",
        "targets = [label for _, label in full_ds.samples]\n",
        "class_names = full_ds.classes\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(targets)),\n",
        "    test_size=0.2,\n",
        "    stratify=targets,\n",
        "    random_state=CFG['SEED']\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = Subset(CustomImageDataset(PATHS[\"TRAIN\"], transform=train_tf, is_test=False), train_idx)\n",
        "val_dataset = Subset(CustomImageDataset(PATHS[\"TRAIN\"], transform=val_tf, is_test=False), val_idx)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "test_root = PATHS[\"TEST\"]\n",
        "test_dataset = CustomImageDataset(test_root, transform=val_tf, is_test=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "print(f\"Number of train imgs: {len(train_dataset)}, Number of valid imgs: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ViT_L_16 (Vision Transformer Large‑16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====================================================================================================\n",
            "Layer (type:depth-idx)                             Output Shape              Param #\n",
            "====================================================================================================\n",
            "VisionTransformer                                  [1, 396]                  1,024\n",
            "├─Conv2d: 1-1                                      [1, 1024, 14, 14]         787,456\n",
            "├─Encoder: 1-2                                     [1, 197, 1024]            201,728\n",
            "│    └─Dropout: 2-1                                [1, 197, 1024]            --\n",
            "│    └─Sequential: 2-2                             [1, 197, 1024]            --\n",
            "│    │    └─EncoderBlock: 3-1                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-2                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-3                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-4                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-5                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-6                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-7                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-8                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-9                      [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-10                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-11                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-12                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-13                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-14                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-15                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-16                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-17                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-18                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-19                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-20                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-21                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-22                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-23                     [1, 197, 1024]            12,596,224\n",
            "│    │    └─EncoderBlock: 3-24                     [1, 197, 1024]            12,596,224\n",
            "│    └─LayerNorm: 2-3                              [1, 197, 1024]            2,048\n",
            "├─Sequential: 1-3                                  [1, 396]                  --\n",
            "│    └─Linear: 2-4                                 [1, 396]                  405,900\n",
            "====================================================================================================\n",
            "Total params: 303,707,532\n",
            "Trainable params: 303,707,532\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 356.30\n",
            "====================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 274.35\n",
            "Params size (MB): 810.97\n",
            "Estimated Total Size (MB): 1085.92\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "weights = ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1\n",
        "model   = vit_l_16(weights=weights)\n",
        "\n",
        "in_features = model.heads.head.in_features\n",
        "model.heads.head = nn.Linear(in_features, CFG['NUM_CLASSES'])\n",
        "\n",
        "print(summary(model, input_size=(1, 3, CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"],)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Hyper-params**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv6vSEwcYBF2"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=CFG[\"LR\"], weight_decay=CFG[\"WEIGHT_DECAY\"])\n",
        "\n",
        "steps_per_epoch = len(train_loader)\n",
        "warmup_steps = 5 * steps_per_epoch\n",
        "\n",
        "def lr_lambda(step):\n",
        "    if step < warmup_steps:\n",
        "        return step / float(max(1, warmup_steps))\n",
        "    progress = (step - warmup_steps) / float(max(1, CFG[\"EPOCHS\"] * steps_per_epoch - warmup_steps))\n",
        "    return 0.5 * (1.0 + torch.cos(torch.pi * torch.tensor(progress)))\n",
        "\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience: int = 5, delta: float = 0.0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best = None\n",
        "        self.counter = 0\n",
        "        self.stop = False\n",
        "\n",
        "    def __call__(self, metric: float):\n",
        "        if self.best is None or metric < self.best - self.delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.stop = True\n",
        "\n",
        "early_stopper = EarlyStopping(patience=CFG[\"PATIENCE\"], delta=0.001)\n",
        "\n",
        "\n",
        "log_file = PATHS[\"LOG\"] / \"train_ViT_Large_250612.log\"\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s %(message)s\",\n",
        "    handlers=[\n",
        "        logging.StreamHandler(),\n",
        "        logging.FileHandler(log_file, mode=\"w\"),\n",
        "    ],\n",
        ")\n",
        "logger = logging.getLogger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Train net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRkN_fcGYs0J",
        "outputId": "5868d889-ffbe-4cc5-996f-8ad648e210d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 09:26:57,690 Epoch 1/500 | Time 1181.1s | TrainLoss 5.9798 | ValLoss 5.9740 | ValAcc 0.42% | LogLoss 5.9722\n",
            "2025-06-12 09:26:59,025 [Checkpoint] Saved at epoch 1 (LogLoss 5.9722)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 09:51:30,205 Epoch 2/500 | Time 1471.2s | TrainLoss 5.9397 | ValLoss 5.9828 | ValAcc 0.41% | LogLoss 5.9737\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 10:15:47,491 Epoch 3/500 | Time 1457.3s | TrainLoss 5.8057 | ValLoss 5.6640 | ValAcc 1.39% | LogLoss 5.5948\n",
            "2025-06-12 10:15:49,042 [Checkpoint] Saved at epoch 3 (LogLoss 5.5948)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 10:37:25,184 Epoch 4/500 | Time 1296.1s | TrainLoss 5.5880 | ValLoss 5.3611 | ValAcc 2.75% | LogLoss 5.2130\n",
            "2025-06-12 10:37:26,674 [Checkpoint] Saved at epoch 4 (LogLoss 5.2130)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 10:58:46,487 Epoch 5/500 | Time 1279.8s | TrainLoss 5.2398 | ValLoss 5.0215 | ValAcc 6.41% | LogLoss 4.7901\n",
            "2025-06-12 10:58:48,004 [Checkpoint] Saved at epoch 5 (LogLoss 4.7901)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 11:20:03,663 Epoch 6/500 | Time 1275.7s | TrainLoss 4.7887 | ValLoss 4.4080 | ValAcc 13.39% | LogLoss 4.0176\n",
            "2025-06-12 11:20:05,182 [Checkpoint] Saved at epoch 6 (LogLoss 4.0176)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 11:40:44,804 Epoch 7/500 | Time 1239.6s | TrainLoss 4.2596 | ValLoss 3.9200 | ValAcc 21.99% | LogLoss 3.4265\n",
            "2025-06-12 11:40:46,219 [Checkpoint] Saved at epoch 7 (LogLoss 3.4265)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 11:59:30,439 Epoch 8/500 | Time 1124.2s | TrainLoss 3.7392 | ValLoss 3.5382 | ValAcc 32.56% | LogLoss 2.9589\n",
            "2025-06-12 11:59:31,855 [Checkpoint] Saved at epoch 8 (LogLoss 2.9589)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 12:18:23,178 Epoch 9/500 | Time 1131.3s | TrainLoss 3.2795 | ValLoss 3.1198 | ValAcc 42.94% | LogLoss 2.4440\n",
            "2025-06-12 12:18:24,592 [Checkpoint] Saved at epoch 9 (LogLoss 2.4440)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 12:37:15,928 Epoch 10/500 | Time 1131.3s | TrainLoss 2.8850 | ValLoss 2.8397 | ValAcc 49.71% | LogLoss 2.1106\n",
            "2025-06-12 12:37:17,394 [Checkpoint] Saved at epoch 10 (LogLoss 2.1106)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 12:55:57,754 Epoch 11/500 | Time 1120.4s | TrainLoss 2.5878 | ValLoss 2.6416 | ValAcc 55.05% | LogLoss 1.8585\n",
            "2025-06-12 12:55:59,169 [Checkpoint] Saved at epoch 11 (LogLoss 1.8585)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 13:13:41,453 Epoch 12/500 | Time 1062.3s | TrainLoss 2.3308 | ValLoss 2.4725 | ValAcc 58.98% | LogLoss 1.6629\n",
            "2025-06-12 13:13:42,650 [Checkpoint] Saved at epoch 12 (LogLoss 1.6629)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 13:27:33,761 Epoch 13/500 | Time 831.1s | TrainLoss 2.1458 | ValLoss 2.3503 | ValAcc 62.75% | LogLoss 1.5226\n",
            "2025-06-12 13:27:35,027 [Checkpoint] Saved at epoch 13 (LogLoss 1.5226)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 13:41:25,327 Epoch 14/500 | Time 830.3s | TrainLoss 1.9770 | ValLoss 2.2455 | ValAcc 66.17% | LogLoss 1.3938\n",
            "2025-06-12 13:41:26,735 [Checkpoint] Saved at epoch 14 (LogLoss 1.3938)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 13:55:14,788 Epoch 15/500 | Time 828.1s | TrainLoss 1.9051 | ValLoss 2.1999 | ValAcc 67.86% | LogLoss 1.3563\n",
            "2025-06-12 13:55:16,011 [Checkpoint] Saved at epoch 15 (LogLoss 1.3563)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 14:09:03,358 Epoch 16/500 | Time 827.3s | TrainLoss 1.7394 | ValLoss 2.1270 | ValAcc 69.57% | LogLoss 1.2840\n",
            "2025-06-12 14:09:04,600 [Checkpoint] Saved at epoch 16 (LogLoss 1.2840)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 14:22:54,970 Epoch 17/500 | Time 830.4s | TrainLoss 1.6450 | ValLoss 2.1243 | ValAcc 69.58% | LogLoss 1.2832\n",
            "2025-06-12 14:22:56,270 [Checkpoint] Saved at epoch 17 (LogLoss 1.2832)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 14:44:11,085 Epoch 18/500 | Time 1274.8s | TrainLoss 1.5758 | ValLoss 2.0826 | ValAcc 70.88% | LogLoss 1.2699\n",
            "2025-06-12 14:44:12,629 [Checkpoint] Saved at epoch 18 (LogLoss 1.2699)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 15:27:39,133 Epoch 19/500 | Time 2606.5s | TrainLoss 1.5293 | ValLoss 2.0758 | ValAcc 71.15% | LogLoss 1.2637\n",
            "2025-06-12 15:27:40,626 [Checkpoint] Saved at epoch 19 (LogLoss 1.2637)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 16:11:35,406 Epoch 20/500 | Time 2634.8s | TrainLoss 1.4673 | ValLoss 2.0088 | ValAcc 72.77% | LogLoss 1.2040\n",
            "2025-06-12 16:11:36,920 [Checkpoint] Saved at epoch 20 (LogLoss 1.2040)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 16:53:56,250 Epoch 21/500 | Time 2539.3s | TrainLoss 1.4449 | ValLoss 2.0171 | ValAcc 72.89% | LogLoss 1.1976\n",
            "2025-06-12 16:53:57,793 [Checkpoint] Saved at epoch 21 (LogLoss 1.1976)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 17:34:57,166 Epoch 22/500 | Time 2459.4s | TrainLoss 1.4042 | ValLoss 1.9794 | ValAcc 73.30% | LogLoss 1.1606\n",
            "2025-06-12 17:34:58,756 [Checkpoint] Saved at epoch 22 (LogLoss 1.1606)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 18:16:01,279 Epoch 23/500 | Time 2462.5s | TrainLoss 1.3788 | ValLoss 1.9674 | ValAcc 74.37% | LogLoss 1.1774\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 18:52:26,840 Epoch 24/500 | Time 2185.6s | TrainLoss 1.3296 | ValLoss 1.9339 | ValAcc 75.29% | LogLoss 1.1413\n",
            "2025-06-12 18:52:28,281 [Checkpoint] Saved at epoch 24 (LogLoss 1.1413)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 19:28:47,455 Epoch 25/500 | Time 2179.2s | TrainLoss 1.3177 | ValLoss 1.9204 | ValAcc 75.90% | LogLoss 1.1313\n",
            "2025-06-12 19:28:48,955 [Checkpoint] Saved at epoch 25 (LogLoss 1.1313)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 20:05:03,602 Epoch 26/500 | Time 2174.6s | TrainLoss 1.2929 | ValLoss 1.9202 | ValAcc 75.51% | LogLoss 1.1419\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 20:41:12,941 Epoch 27/500 | Time 2169.3s | TrainLoss 1.2769 | ValLoss 1.8974 | ValAcc 76.41% | LogLoss 1.1112\n",
            "2025-06-12 20:41:14,411 [Checkpoint] Saved at epoch 27 (LogLoss 1.1112)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 21:17:42,676 Epoch 28/500 | Time 2188.3s | TrainLoss 1.2546 | ValLoss 1.8660 | ValAcc 77.83% | LogLoss 1.1124\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 21:53:23,538 Epoch 29/500 | Time 2140.9s | TrainLoss 1.2366 | ValLoss 1.8643 | ValAcc 77.73% | LogLoss 1.1079\n",
            "2025-06-12 21:53:25,096 [Checkpoint] Saved at epoch 29 (LogLoss 1.1079)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 22:29:44,209 Epoch 30/500 | Time 2179.1s | TrainLoss 1.2333 | ValLoss 1.8640 | ValAcc 76.91% | LogLoss 1.1058\n",
            "2025-06-12 22:29:45,694 [Checkpoint] Saved at epoch 30 (LogLoss 1.1058)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 23:06:04,672 Epoch 31/500 | Time 2179.0s | TrainLoss 1.2213 | ValLoss 1.8489 | ValAcc 77.50% | LogLoss 1.0922\n",
            "2025-06-12 23:06:06,166 [Checkpoint] Saved at epoch 31 (LogLoss 1.0922)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 23:42:17,914 Epoch 32/500 | Time 2171.7s | TrainLoss 1.2015 | ValLoss 1.8293 | ValAcc 78.18% | LogLoss 1.0752\n",
            "2025-06-12 23:42:19,392 [Checkpoint] Saved at epoch 32 (LogLoss 1.0752)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 00:14:22,406 Epoch 33/500 | Time 1923.0s | TrainLoss 1.1854 | ValLoss 1.8436 | ValAcc 77.11% | LogLoss 1.0958\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 00:42:47,296 Epoch 34/500 | Time 1704.9s | TrainLoss 1.1828 | ValLoss 1.8368 | ValAcc 77.79% | LogLoss 1.0928\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 01:11:12,144 Epoch 35/500 | Time 1704.8s | TrainLoss 1.1727 | ValLoss 1.8360 | ValAcc 77.71% | LogLoss 1.0974\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 01:39:37,074 Epoch 36/500 | Time 1704.9s | TrainLoss 1.1637 | ValLoss 1.8165 | ValAcc 78.38% | LogLoss 1.0752\n",
            "2025-06-13 01:39:38,476 [Checkpoint] Saved at epoch 36 (LogLoss 1.0752)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 02:07:52,968 Epoch 37/500 | Time 1694.5s | TrainLoss 1.1523 | ValLoss 1.8146 | ValAcc 78.50% | LogLoss 1.0742\n",
            "2025-06-13 02:07:54,375 [Checkpoint] Saved at epoch 37 (LogLoss 1.0742)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 02:36:11,350 Epoch 38/500 | Time 1697.0s | TrainLoss 1.1469 | ValLoss 1.8340 | ValAcc 77.58% | LogLoss 1.0874\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 03:04:40,704 Epoch 39/500 | Time 1709.4s | TrainLoss 1.1325 | ValLoss 1.7872 | ValAcc 79.30% | LogLoss 1.0616\n",
            "2025-06-13 03:04:42,087 [Checkpoint] Saved at epoch 39 (LogLoss 1.0616)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 03:33:02,876 Epoch 40/500 | Time 1700.8s | TrainLoss 1.1260 | ValLoss 1.7764 | ValAcc 79.60% | LogLoss 1.0476\n",
            "2025-06-13 03:33:04,266 [Checkpoint] Saved at epoch 40 (LogLoss 1.0476)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 04:01:27,241 Epoch 41/500 | Time 1703.0s | TrainLoss 1.1240 | ValLoss 1.7534 | ValAcc 79.78% | LogLoss 1.0134\n",
            "2025-06-13 04:01:28,645 [Checkpoint] Saved at epoch 41 (LogLoss 1.0134)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 04:29:46,593 Epoch 42/500 | Time 1697.9s | TrainLoss 1.1168 | ValLoss 1.7669 | ValAcc 78.71% | LogLoss 1.0360\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 04:58:10,513 Epoch 43/500 | Time 1703.9s | TrainLoss 1.1113 | ValLoss 1.7532 | ValAcc 79.60% | LogLoss 1.0274\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 05:26:36,640 Epoch 44/500 | Time 1706.1s | TrainLoss 1.1149 | ValLoss 1.8060 | ValAcc 78.47% | LogLoss 1.0951\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 05:55:02,090 Epoch 45/500 | Time 1705.4s | TrainLoss 1.0979 | ValLoss 1.7530 | ValAcc 79.56% | LogLoss 1.0349\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-13 06:23:29,741 Epoch 46/500 | Time 1707.7s | TrainLoss 1.0999 | ValLoss 1.7796 | ValAcc 78.03% | LogLoss 1.0616\n",
            "2025-06-13 06:23:29,742 Early stopping triggered.\n",
            "2025-06-13 06:23:29,743 Total training time: 21:16:13\n"
          ]
        }
      ],
      "source": [
        "def train_one_epoch(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f\"[{epoch}/{CFG['EPOCHS']}] Train\", leave=False)\n",
        "    for step, (imgs, labels) in enumerate(pbar, start=1):\n",
        "        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.4f}\"})\n",
        "\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "def validate(epoch):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_probs, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            \n",
        "            val_loss += loss.item()\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            all_probs.append(F.softmax(logits, dim=1).cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "\n",
        "    class_idx = list(range(CFG[\"NUM_CLASSES\"]))\n",
        "    answer_df = pd.DataFrame({\"ID\": np.arange(len(all_labels)), \"label\": all_labels})\n",
        "    submission_df = pd.DataFrame(all_probs, columns=class_idx)\n",
        "    submission_df.insert(0, \"ID\", submission_df.index)\n",
        "    logloss = log_loss(answer_df[\"label\"], all_probs, labels=class_idx)\n",
        "\n",
        "    return val_loss / len(val_loader), acc, logloss\n",
        "\n",
        "\n",
        "BEST_LOSS = float(\"inf\")\n",
        "start = time.time()\n",
        "for epoch in range(1, CFG[\"EPOCHS\"] + 1):\n",
        "    t0 = time.time()\n",
        "    tr_loss = train_one_epoch(epoch)\n",
        "    val_loss, val_acc, val_logloss = validate(epoch)\n",
        "    epoch_dur = time.time() - t0\n",
        "\n",
        "    logger.info(\n",
        "        f\"Epoch {epoch}/{CFG['EPOCHS']} | \"\n",
        "        f\"Time {epoch_dur:.1f}s | \"\n",
        "        f\"TrainLoss {tr_loss:.4f} | ValLoss {val_loss:.4f} | \"\n",
        "        f\"ValAcc {val_acc:.2f}% | LogLoss {val_logloss:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Save best by logloss\n",
        "    if val_logloss < BEST_LOSS:\n",
        "        BEST_LOSS = val_logloss\n",
        "        ckpt_path = PATHS[\"CKPT\"] / \"best_ViT_Large_250612_b32.pth\"\n",
        "        torch.save(model.state_dict(), ckpt_path)\n",
        "        logger.info(f\"[Checkpoint] Saved at epoch {epoch} (LogLoss {BEST_LOSS:.4f})\")\n",
        "\n",
        "    early_stopper(val_logloss)\n",
        "    if early_stopper.stop:\n",
        "        logger.info(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "logger.info(f\"Total training time: {datetime.timedelta(seconds=int(time.time() - start))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Eval**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJJe3UnEgA6y"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "# 저장된 모델 로드\n",
        "weights = ViT_L_16_Weights.IMAGENET1K_SWAG_LINEAR_V1\n",
        "model   = vit_l_16(weights=weights)\n",
        "in_features = model.heads.head.in_features\n",
        "model.heads.head = nn.Linear(in_features, CFG['NUM_CLASSES'])\n",
        "\n",
        "model.load_state_dict(torch.load(PATHS[\"CKPT\"] / \"best_ViT_Large_250612_b32.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, filenames in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        for prob in probs.cpu():\n",
        "            result = {\n",
        "                class_names[i]: prob[i].item()\n",
        "                for i in range(len(class_names))\n",
        "            }\n",
        "            results.append(result)\n",
        "            \n",
        "pred = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Submission\n",
        "submission = pd.read_csv(os.path.join(PATHS[\"SUBMIT\"], 'submission_JN.csv'), encoding='utf-8-sig')\n",
        "\n",
        "class_columns = submission.columns[1:]\n",
        "pred = pred[class_columns]\n",
        "\n",
        "submission[class_columns] = pred.values\n",
        "submission.to_csv(os.path.join(PATHS[\"SUBMIT\"], 'ViT_Large_250612_b32_submission_JN.csv'), index=False, encoding='utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO3li9OAnGka1if4d+usg7h",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1tXZe3gyQHzQnlNjadpS1QxSHl-_dRwZL",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "HAI_project",
      "language": "python",
      "name": "hai_project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
