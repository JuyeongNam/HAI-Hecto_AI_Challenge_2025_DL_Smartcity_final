{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1tXZe3gyQHzQnlNjadpS1QxSHl-_dRwZL",
      "authorship_tag": "ABX9TyO3li9OAnGka1if4d+usg7h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuyeongNam/HAI-Hecto_AI_Challenge_2025_DL_Smartcity_final/blob/main/pilot_JNam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "import torchvision.transforms as transforms\n",
        "import timm"
      ],
      "metadata": {
        "id": "OdM98q3YTu9q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'Img_size': 224,\n",
        "    'Batch_size': 8,\n",
        "    'EPOCHS': 3,\n",
        "    'Learning_rate': 1e-4,\n",
        "    'Weight_decay': 1e-4,\n",
        "    'SEED': 42,\n",
        "    'Num_class' : 396\n",
        "}"
      ],
      "metadata": {
        "id": "h_z37-sCVW_6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range(CFG['Num_class']), range(396)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbe4DprzUtar",
        "outputId": "28a1698f-0682-4f8a-f460-ebdc3cdb7a13"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(range(0, 396), range(0, 396))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED'])\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "FXjhJninT2py"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fdr2jbS-Oixh"
      },
      "outputs": [],
      "source": [
        "# 1. CustomImageDataset 클래스 정의\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_test=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.samples = []\n",
        "\n",
        "        if self.is_test:\n",
        "            # Test: 이미지 파일 경로만 저장 (레이블 없음)\n",
        "            for fname in sorted(os.listdir(root_dir)):\n",
        "                if fname.lower().endswith('.jpg'):\n",
        "                    img_path = os.path.join(root_dir, fname)\n",
        "                    self.samples.append((img_path,))\n",
        "        else:\n",
        "            # Train/Validation: 폴더 구조에서 클래스별 레이블 추출\n",
        "            self.classes = sorted(os.listdir(root_dir))\n",
        "            self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "            for cls_name in self.classes:\n",
        "                cls_folder = os.path.join(root_dir, cls_name)\n",
        "                for fname in os.listdir(cls_folder):\n",
        "                    if fname.lower().endswith('.jpg'):\n",
        "                        img_path = os.path.join(cls_folder, fname)\n",
        "                        label = self.class_to_idx[cls_name]\n",
        "                        self.samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            img_path = self.samples[idx][0]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, os.path.basename(img_path)  # (image, filename) 반환\n",
        "        else:\n",
        "            img_path, label = self.samples[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "\n",
        "# 2. 데이터 전처리(Transforms) 정의\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((CFG['Img_size'], CFG['Img_size']), scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['Img_size'], CFG['Img_size'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['Img_size'], CFG['Img_size'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 데이터셋 로딩 및 학습/검증 셋 분리\n",
        "train_root = '/content/drive/MyDrive/DL_Smartcity_final/sample_data/train'\n",
        "full_dataset = CustomImageDataset(train_root, transform=None, is_test=False)\n",
        "print(f\"총 이미지 수 (전체): {len(full_dataset)}\")\n",
        "\n",
        "# 레이블만 추출하여 Stratified Split 진행\n",
        "targets = [label for _, label in full_dataset.samples]\n",
        "class_names = full_dataset.classes\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(targets)),\n",
        "    test_size=0.2,\n",
        "    stratify=targets,\n",
        "    random_state=CFG['SEED']\n",
        ")\n",
        "\n",
        "# Subset을 활용하여 Transform을 적용한 Dataset 생성\n",
        "train_dataset = Subset(CustomImageDataset(train_root, transform=train_transform, is_test=False), train_idx)\n",
        "val_dataset = Subset(CustomImageDataset(train_root, transform=val_transform, is_test=False), val_idx)\n",
        "\n",
        "print(f\"Train 이미지 개수: {len(train_dataset)}, Valid 이미지 개수: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKc8X1W9UL1d",
        "outputId": "910f38aa-c1fd-4b4d-dcb5-5604176242e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 이미지 수 (전체): 3106\n",
            "Train 이미지 개수: 2484, Valid 이미지 개수: 622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. DataLoader 정의\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG['Batch_size'], shuffle=True, num_workers=0)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=CFG['Batch_size'], shuffle=False, num_workers=0)\n",
        "\n",
        "# 5. 테스트용 DataLoader 정의\n",
        "test_root = '/content/drive/MyDrive/DL_Smartcity_final/sample_data/test'\n",
        "test_dataset = CustomImageDataset(test_root, transform=val_transform, is_test=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=CFG['Batch_size'], shuffle=False, num_workers=0)"
      ],
      "metadata": {
        "id": "Pyrx5jblWF9r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = Subset(CustomImageDataset(train_root, transform=test_transform, is_test=False), val_idx)\n",
        "val_loader  = DataLoader(val_dataset, batch_size=CFG['Batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "# 검증용 배치 예시\n",
        "images_val, labels_val = next(iter(val_loader))\n",
        "print(f\"Valid Batch 이미지 크기: {images_val.shape}, 레이블 예시: {labels_val.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okADRwrIVPR1",
        "outputId": "cff01878-45cb-43db-e9ec-7a5b408479a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid Batch 이미지 크기: torch.Size([8, 3, 224, 224]), 레이블 예시: [272, 196, 388, 129, 234, 370, 34, 107]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNetModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(DenseNetModel, self).__init__()\n",
        "        self.backbone = models.densenet121(pretrained=True)\n",
        "        in_features = self.backbone.classifier.in_features\n",
        "        self.backbone.classifier = nn.Identity()\n",
        "        self.head = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "WtUc81CWWk3a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNKdJEa0Xpof",
        "outputId": "08faffa6-5809-4fe4-d9a3-95bccc45db0d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "model = DenseNetModel(num_classes=CFG['Num_class'])\n",
        "summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTeH8swWXURW",
        "outputId": "d29ebaea-9886-4609-9071-1125f2c732fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 129MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "======================================================================\n",
              "Layer (type:depth-idx)                        Param #\n",
              "======================================================================\n",
              "DenseNetModel                                 --\n",
              "├─DenseNet: 1-1                               --\n",
              "│    └─Sequential: 2-1                        --\n",
              "│    │    └─Conv2d: 3-1                       9,408\n",
              "│    │    └─BatchNorm2d: 3-2                  128\n",
              "│    │    └─ReLU: 3-3                         --\n",
              "│    │    └─MaxPool2d: 3-4                    --\n",
              "│    │    └─_DenseBlock: 3-5                  335,040\n",
              "│    │    └─_Transition: 3-6                  33,280\n",
              "│    │    └─_DenseBlock: 3-7                  919,680\n",
              "│    │    └─_Transition: 3-8                  132,096\n",
              "│    │    └─_DenseBlock: 3-9                  2,837,760\n",
              "│    │    └─_Transition: 3-10                 526,336\n",
              "│    │    └─_DenseBlock: 3-11                 2,158,080\n",
              "│    │    └─BatchNorm2d: 3-12                 2,048\n",
              "│    └─Identity: 2-2                          --\n",
              "├─Linear: 1-2                                 405,900\n",
              "======================================================================\n",
              "Total params: 7,359,756\n",
              "Trainable params: 7,359,756\n",
              "Non-trainable params: 0\n",
              "======================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "\n",
        "# (3) 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=CFG['Learning_rate'],\n",
        "    weight_decay=CFG['Weight_decay']\n",
        ")\n",
        "\n",
        "# (4) Learning Rate 스케줄러 (선택 사항)\n",
        "#    여기서는 간단히 CosineAnnealingLR을 예시로 추가했습니다.\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                T_max=CFG['EPOCHS'],\n",
        "                                                eta_min=1e-6)"
      ],
      "metadata": {
        "id": "Fv6vSEwcYBF2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_logloss = float('inf')\n",
        "\n",
        "for epoch in range(1, CFG['EPOCHS'] + 1):\n",
        "    # === 5-1. Train 단계 ===\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"[Epoch {epoch}/{CFG['EPOCHS']}] Train\"):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)           # 로짓(logits) 크기: (B, num_classes)\n",
        "        loss = criterion(outputs, labels) # CrossEntropyLoss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # === 5-2. Validation 단계 ===\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_probs = []   # 검증용 확률(softmax) 저장\n",
        "    all_labels = []  # 검증용 실제 라벨 저장\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(val_loader, desc=f\"[Epoch {epoch}/{CFG['EPOCHS']}] Valid\"):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            # 정확도 계산\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # LogLoss 계산을 위한 확률과 실제 라벨 저장\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_logloss = log_loss(y_true=all_labels,\n",
        "                           y_pred=all_probs,\n",
        "                           labels=list(range(CFG['Num_class'])))\n",
        "\n",
        "    # 스케줄러 한 스텝(step) 업데이트\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\n",
        "        f\"\\nEpoch {epoch}/{CFG['EPOCHS']} ▶ \"\n",
        "        f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Valid Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Valid Acc: {val_accuracy:.2f}% | \"\n",
        "        f\"Valid LogLoss: {val_logloss:.4f}\"\n",
        "    )\n",
        "\n",
        "    # 검증 LogLoss 기준으로 최고 성능 모델 저장\n",
        "    if val_logloss < best_val_logloss:\n",
        "        best_val_logloss = val_logloss\n",
        "        torch.save(model.state_dict(), 'best_densenet121.pth')\n",
        "        print(f\"📦 [모델 저장] Epoch {epoch} 에서 LogLoss {val_logloss:.4f} 달성\\n\")\n",
        "    else:\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRkN_fcGYs0J",
        "outputId": "5868d889-ffbe-4cc5-996f-8ad648e210d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 1/3] Train: 100%|██████████| 311/311 [33:10<00:00,  6.40s/it]\n",
            "[Epoch 1/3] Valid: 100%|██████████| 78/78 [04:00<00:00,  3.08s/it]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3 ▶ Train Loss: 6.2340 | Valid Loss: 5.9018 | Valid Acc: 1.61% | Valid LogLoss: 5.9024\n",
            "📦 [모델 저장] Epoch 1 에서 LogLoss 5.9024 달성\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 2/3] Train: 100%|██████████| 311/311 [01:07<00:00,  4.58it/s]\n",
            "[Epoch 2/3] Valid: 100%|██████████| 78/78 [00:05<00:00, 13.89it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/3 ▶ Train Loss: 5.6559 | Valid Loss: 5.4829 | Valid Acc: 6.27% | Valid LogLoss: 5.4830\n",
            "📦 [모델 저장] Epoch 2 에서 LogLoss 5.4830 달성\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 3/3] Train: 100%|██████████| 311/311 [01:12<00:00,  4.28it/s]\n",
            "[Epoch 3/3] Valid: 100%|██████████| 78/78 [00:05<00:00, 14.11it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/3 ▶ Train Loss: 5.1528 | Valid Loss: 5.3190 | Valid Acc: 8.68% | Valid LogLoss: 5.3190\n",
            "📦 [모델 저장] Epoch 3 에서 LogLoss 5.3190 달성\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJJe3UnEgA6y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
