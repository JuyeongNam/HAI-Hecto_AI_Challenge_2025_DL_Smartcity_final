{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OdM98q3YTu9q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.models import regnet_y_128gf, RegNet_Y_128GF_Weights\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "from torchinfo import summary\n",
        "from tqdm import tqdm\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GPU_NUM = 0\n",
        "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.set_device(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Config**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h_z37-sCVW_6"
      },
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    \"IMG_SIZE\": 224,\n",
        "    \"NUM_CLASSES\": 396,\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"EPOCHS\": 500,\n",
        "    \"LR\": 1e-4,\n",
        "    \"WEIGHT_DECAY\": 1e-2,\n",
        "    \"PATIENCE\": 5,\n",
        "    \"SEED\": 42,\n",
        "    # AMP & Grad‑clip\n",
        "    \"USE_AMP\": False,\n",
        "    \"GRAD_CLIP\": 1.0,\n",
        "}\n",
        "\n",
        "BASE_DIR = Path(r\"D:/dacon_HAI\")\n",
        "PATHS = {\n",
        "    \"BASE\": BASE_DIR,\n",
        "    \"TRAIN\": BASE_DIR / \"open\" / \"train\",\n",
        "    \"TEST\":  BASE_DIR / \"open\" / \"test\",\n",
        "    \"CKPT\":  BASE_DIR / \"checkpoints\",\n",
        "    \"LOG\":   BASE_DIR / \"logs\",\n",
        "    \"SUBMIT\": BASE_DIR / \"submission\",\n",
        "}\n",
        "for p in PATHS.values():\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- Normalization stats ---\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FXjhJninT2py"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "seed_everything(CFG[\"SEED\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdr2jbS-Oixh"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_test=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.samples = []\n",
        "\n",
        "        if self.is_test:\n",
        "            for fname in sorted(os.listdir(root_dir)):\n",
        "                if fname.lower().endswith('.jpg'):\n",
        "                    img_path = os.path.join(root_dir, fname)\n",
        "                    self.samples.append((img_path,))\n",
        "        else:\n",
        "            self.classes = sorted(os.listdir(root_dir))\n",
        "            self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "            for cls_name in self.classes:\n",
        "                cls_folder = os.path.join(root_dir, cls_name)\n",
        "                for fname in os.listdir(cls_folder):\n",
        "                    if fname.lower().endswith('.jpg'):\n",
        "                        img_path = os.path.join(cls_folder, fname)\n",
        "                        label = self.class_to_idx[cls_name]\n",
        "                        self.samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            img_path = self.samples[idx][0]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, os.path.basename(img_path)\n",
        "        else:\n",
        "            img_path, label = self.samples[idx]\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "\n",
        "spatial_aug = transforms.RandomChoice([\n",
        "    transforms.RandomResizedCrop(CFG[\"IMG_SIZE\"], scale=(0.8, 1.0)),\n",
        "    transforms.CenterCrop(CFG[\"IMG_SIZE\"]),\n",
        "])\n",
        "geom_aug = transforms.RandomChoice([\n",
        "    transforms.RandomHorizontalFlip(p=1.0),\n",
        "    transforms.RandomVerticalFlip(p=1.0),\n",
        "    transforms.RandomRotation(degrees=(-30, 30), interpolation=transforms.InterpolationMode.BILINEAR, fill=0),\n",
        "])\n",
        "pixel_aug = transforms.RandomChoice([\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 5.0)),\n",
        "    transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
        "])\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n",
        "    transforms.RandomApply([spatial_aug], p=0.5),\n",
        "    transforms.RandomApply([geom_aug],    p=0.5),\n",
        "    transforms.RandomApply([pixel_aug],   p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKc8X1W9UL1d",
        "outputId": "910f38aa-c1fd-4b4d-dcb5-5604176242e0"
      },
      "outputs": [],
      "source": [
        "full_ds = CustomImageDataset(PATHS[\"TRAIN\"], transform=train_tf, is_test=False)\n",
        "print(f\"Full data: {len(full_ds):,}\")\n",
        "\n",
        "targets = [label for _, label in full_ds.samples]\n",
        "class_names = full_ds.classes\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(targets)),\n",
        "    test_size=0.2,\n",
        "    stratify=targets,\n",
        "    random_state=CFG['SEED']\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = Subset(CustomImageDataset(PATHS[\"TRAIN\"], transform=train_tf, is_test=False), train_idx)\n",
        "val_dataset = Subset(CustomImageDataset(PATHS[\"TRAIN\"], transform=val_tf, is_test=False), val_idx)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "test_root = PATHS[\"TEST\"]\n",
        "test_dataset = CustomImageDataset(test_root, transform=val_tf, is_test=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "print(f\"Number of train imgs: {len(train_dataset)}, Number of valid imgs: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RegNet_Y_128GF (SWAG E2E variant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================================================================================================\n",
            "Layer (type:depth-idx)                                  Output Shape              Param #\n",
            "=========================================================================================================\n",
            "RegNet                                                  [1, 396]                  --\n",
            "├─SimpleStemIN: 1-1                                     [1, 32, 112, 112]         --\n",
            "│    └─Conv2d: 2-1                                      [1, 32, 112, 112]         864\n",
            "│    └─BatchNorm2d: 2-2                                 [1, 32, 112, 112]         64\n",
            "│    └─ReLU: 2-3                                        [1, 32, 112, 112]         --\n",
            "├─Sequential: 1-2                                       [1, 7392, 7, 7]           --\n",
            "│    └─AnyStage: 2-4                                    [1, 528, 56, 56]          --\n",
            "│    │    └─ResBottleneckBlock: 3-1                     [1, 528, 56, 56]          1,580,312\n",
            "│    │    └─ResBottleneckBlock: 3-2                     [1, 528, 56, 56]          1,955,316\n",
            "│    └─AnyStage: 2-5                                    [1, 1056, 28, 28]         --\n",
            "│    │    └─ResBottleneckBlock: 3-3                     [1, 1056, 28, 28]         5,027,748\n",
            "│    │    └─ResBottleneckBlock: 3-4                     [1, 1056, 28, 28]         5,304,552\n",
            "│    │    └─ResBottleneckBlock: 3-5                     [1, 1056, 28, 28]         5,304,552\n",
            "│    │    └─ResBottleneckBlock: 3-6                     [1, 1056, 28, 28]         5,304,552\n",
            "│    │    └─ResBottleneckBlock: 3-7                     [1, 1056, 28, 28]         5,304,552\n",
            "│    │    └─ResBottleneckBlock: 3-8                     [1, 1056, 28, 28]         5,304,552\n",
            "│    │    └─ResBottleneckBlock: 3-9                     [1, 1056, 28, 28]         5,304,552\n",
            "│    └─AnyStage: 2-6                                    [1, 2904, 14, 14]         --\n",
            "│    │    └─ResBottleneckBlock: 3-10                    [1, 2904, 14, 14]         23,026,080\n",
            "│    │    └─ResBottleneckBlock: 3-11                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-12                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-13                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-14                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-15                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-16                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-17                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-18                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-19                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-20                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-21                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-22                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-23                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-24                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-25                    [1, 2904, 14, 14]         28,003,998\n",
            "│    │    └─ResBottleneckBlock: 3-26                    [1, 2904, 14, 14]         28,003,998\n",
            "│    └─AnyStage: 2-7                                    [1, 7392, 7, 7]           --\n",
            "│    │    └─ResBottleneckBlock: 3-27                    [1, 7392, 7, 7]           125,938,230\n",
            "├─AdaptiveAvgPool2d: 1-3                                [1, 7392, 1, 1]           --\n",
            "├─Linear: 1-4                                           [1, 396]                  2,927,628\n",
            "=========================================================================================================\n",
            "Total params: 640,347,522\n",
            "Trainable params: 640,347,522\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (G): 127.51\n",
            "=========================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 1144.60\n",
            "Params size (MB): 2561.39\n",
            "Estimated Total Size (MB): 3706.60\n",
            "=========================================================================================================\n"
          ]
        }
      ],
      "source": [
        "weights = RegNet_Y_128GF_Weights.IMAGENET1K_SWAG_LINEAR_V1\n",
        "model = regnet_y_128gf(weights=weights)\n",
        "model.fc = nn.Linear(model.fc.in_features, CFG[\"NUM_CLASSES\"])\n",
        "print(summary(model, input_size=(1, 3, CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"],)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Hyper-params**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=CFG[\"LR\"], weight_decay=CFG[\"WEIGHT_DECAY\"])\n",
        "\n",
        "steps_per_epoch = len(train_loader)\n",
        "warmup_steps = 5 * steps_per_epoch\n",
        "\n",
        "def lr_lambda(step):\n",
        "    if step < warmup_steps:\n",
        "        return step / float(max(1, warmup_steps))\n",
        "    progress = (step - warmup_steps) / float(max(1, CFG[\"EPOCHS\"] * steps_per_epoch - warmup_steps))\n",
        "    return 0.5 * (1.0 + torch.cos(torch.pi * torch.tensor(progress)))\n",
        "\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv6vSEwcYBF2"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience: int = 5, delta: float = 0.0):\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.best = None\n",
        "        self.counter = 0\n",
        "        self.stop = False\n",
        "\n",
        "    def __call__(self, metric: float):\n",
        "        if self.best is None or metric < self.best - self.delta:\n",
        "            self.best = metric\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.stop = True\n",
        "\n",
        "early_stopper = EarlyStopping(patience=CFG[\"PATIENCE\"], delta=0.001)\n",
        "\n",
        "log_file = PATHS[\"LOG\"] / \"train_regnet_y_128gf_250612.log\"\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s %(message)s\",\n",
        "    handlers=[\n",
        "        logging.StreamHandler(),\n",
        "        logging.FileHandler(log_file, mode=\"w\"),\n",
        "    ],\n",
        ")\n",
        "logger = logging.getLogger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Train net**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 09:18:30,869 Epoch 1/500 | Time 1434.8s | TrainLoss 5.2902 | ValLoss 3.5340 | ValAcc 29.63% | LogLoss 3.1452\n",
            "2025-06-12 09:18:36,032 [Checkpoint] Saved at epoch 1 (LogLoss 3.1452)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 09:43:09,229 Epoch 2/500 | Time 1473.2s | TrainLoss 2.4543 | ValLoss 1.5420 | ValAcc 78.26% | LogLoss 0.7882\n",
            "2025-06-12 09:43:15,024 [Checkpoint] Saved at epoch 2 (LogLoss 0.7882)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 10:07:46,223 Epoch 3/500 | Time 1471.2s | TrainLoss 1.4982 | ValLoss 1.3533 | ValAcc 86.81% | LogLoss 0.5269\n",
            "2025-06-12 10:07:52,598 [Checkpoint] Saved at epoch 3 (LogLoss 0.5269)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 10:30:06,522 Epoch 4/500 | Time 1333.9s | TrainLoss 1.3667 | ValLoss 1.2926 | ValAcc 89.91% | LogLoss 0.4437\n",
            "2025-06-12 10:30:12,026 [Checkpoint] Saved at epoch 4 (LogLoss 0.4437)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 10:50:21,952 Epoch 5/500 | Time 1209.9s | TrainLoss 1.3287 | ValLoss 1.3176 | ValAcc 90.13% | LogLoss 0.4470\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 11:10:25,081 Epoch 6/500 | Time 1203.1s | TrainLoss 1.2633 | ValLoss 1.2377 | ValAcc 92.14% | LogLoss 0.3420\n",
            "2025-06-12 11:10:31,057 [Checkpoint] Saved at epoch 6 (LogLoss 0.3420)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 11:30:30,849 Epoch 7/500 | Time 1199.8s | TrainLoss 1.1928 | ValLoss 1.1866 | ValAcc 93.64% | LogLoss 0.2705\n",
            "2025-06-12 11:30:36,745 [Checkpoint] Saved at epoch 7 (LogLoss 0.2705)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 11:47:56,576 Epoch 8/500 | Time 1039.8s | TrainLoss 1.1688 | ValLoss 1.2633 | ValAcc 92.54% | LogLoss 0.3085\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 12:04:29,047 Epoch 9/500 | Time 992.5s | TrainLoss 1.1599 | ValLoss 1.2057 | ValAcc 93.83% | LogLoss 0.2748\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 12:21:00,587 Epoch 10/500 | Time 991.5s | TrainLoss 1.1165 | ValLoss 1.1863 | ValAcc 94.77% | LogLoss 0.2281\n",
            "2025-06-12 12:21:05,988 [Checkpoint] Saved at epoch 10 (LogLoss 0.2281)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 12:37:37,541 Epoch 11/500 | Time 991.6s | TrainLoss 1.1067 | ValLoss 1.1882 | ValAcc 95.29% | LogLoss 0.2192\n",
            "2025-06-12 12:37:43,474 [Checkpoint] Saved at epoch 11 (LogLoss 0.2192)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 12:54:20,512 Epoch 12/500 | Time 997.0s | TrainLoss 1.1063 | ValLoss 1.2051 | ValAcc 94.79% | LogLoss 0.2650\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 13:10:57,272 Epoch 13/500 | Time 996.8s | TrainLoss 1.0951 | ValLoss 1.1953 | ValAcc 95.63% | LogLoss 0.2210\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 13:27:17,497 Epoch 14/500 | Time 980.2s | TrainLoss 1.0683 | ValLoss 1.2104 | ValAcc 94.62% | LogLoss 0.2385\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 13:43:34,612 Epoch 15/500 | Time 977.1s | TrainLoss 1.0652 | ValLoss 1.1833 | ValAcc 95.56% | LogLoss 0.2088\n",
            "2025-06-12 13:43:39,851 [Checkpoint] Saved at epoch 15 (LogLoss 0.2088)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 13:59:50,448 Epoch 16/500 | Time 970.6s | TrainLoss 1.0731 | ValLoss 1.1618 | ValAcc 95.53% | LogLoss 0.2144\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 14:15:59,519 Epoch 17/500 | Time 969.1s | TrainLoss 1.0496 | ValLoss 1.1575 | ValAcc 96.43% | LogLoss 0.1801\n",
            "2025-06-12 14:16:04,925 [Checkpoint] Saved at epoch 17 (LogLoss 0.1801)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 14:32:47,015 Epoch 18/500 | Time 1002.1s | TrainLoss 1.0526 | ValLoss 1.2281 | ValAcc 94.92% | LogLoss 0.2177\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 14:50:18,591 Epoch 19/500 | Time 1051.6s | TrainLoss 1.0504 | ValLoss 1.1665 | ValAcc 96.16% | LogLoss 0.1971\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 15:08:21,310 Epoch 20/500 | Time 1082.7s | TrainLoss 1.0300 | ValLoss 1.1339 | ValAcc 96.62% | LogLoss 0.1748\n",
            "2025-06-12 15:08:27,441 [Checkpoint] Saved at epoch 20 (LogLoss 0.1748)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 15:27:09,363 Epoch 21/500 | Time 1121.9s | TrainLoss 1.0338 | ValLoss 1.1680 | ValAcc 95.51% | LogLoss 0.2300\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 15:45:05,724 Epoch 22/500 | Time 1076.4s | TrainLoss 1.0195 | ValLoss 1.1356 | ValAcc 96.52% | LogLoss 0.1863\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 16:02:54,574 Epoch 23/500 | Time 1068.8s | TrainLoss 1.0242 | ValLoss 1.1670 | ValAcc 96.28% | LogLoss 0.1851\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 16:20:45,345 Epoch 24/500 | Time 1070.8s | TrainLoss 1.0191 | ValLoss 1.1334 | ValAcc 96.99% | LogLoss 0.1557\n",
            "2025-06-12 16:20:50,355 [Checkpoint] Saved at epoch 24 (LogLoss 0.1557)\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 16:38:32,505 Epoch 25/500 | Time 1062.1s | TrainLoss 1.0138 | ValLoss 1.1453 | ValAcc 96.66% | LogLoss 0.1640\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 16:56:18,765 Epoch 26/500 | Time 1066.3s | TrainLoss 1.0235 | ValLoss 1.1326 | ValAcc 96.69% | LogLoss 0.1828\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 17:13:54,870 Epoch 27/500 | Time 1056.1s | TrainLoss 1.0084 | ValLoss 1.1419 | ValAcc 96.33% | LogLoss 0.1733\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 17:31:31,159 Epoch 28/500 | Time 1056.3s | TrainLoss 1.0065 | ValLoss 1.1705 | ValAcc 96.57% | LogLoss 0.1952\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:302: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  self.y_type_ = type_of_target(y, input_name=\"y\")\n",
            "c:\\Users\\USPD\\anaconda3\\envs\\hai_env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples.\n",
            "  ys_types = set(type_of_target(x) for x in ys)\n",
            "2025-06-12 17:49:25,785 Epoch 29/500 | Time 1074.6s | TrainLoss 0.9976 | ValLoss 1.1515 | ValAcc 96.69% | LogLoss 0.1916\n",
            "2025-06-12 17:49:25,786 Early stopping triggered.\n",
            "2025-06-12 17:49:25,787 Total training time: 8:54:49\n"
          ]
        }
      ],
      "source": [
        "def train_one_epoch(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f\"[{epoch}/{CFG['EPOCHS']}] Train\", leave=False)\n",
        "    for step, (imgs, labels) in enumerate(pbar, start=1):\n",
        "        imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(imgs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.4f}\"})\n",
        "\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "def validate(epoch):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_probs, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "            \n",
        "            val_loss += loss.item()\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            all_probs.append(F.softmax(logits, dim=1).cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    acc = 100. * correct / total\n",
        "    all_probs = np.concatenate(all_probs)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # LogLoss\n",
        "    class_idx = list(range(CFG[\"NUM_CLASSES\"]))\n",
        "    answer_df = pd.DataFrame({\"ID\": np.arange(len(all_labels)), \"label\": all_labels})\n",
        "    submission_df = pd.DataFrame(all_probs, columns=class_idx)\n",
        "    submission_df.insert(0, \"ID\", submission_df.index)\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    logloss = log_loss(answer_df[\"label\"], all_probs, labels=class_idx)\n",
        "\n",
        "    return avg_val_loss, acc, logloss\n",
        "\n",
        "\n",
        "BEST_LOSS = float(\"inf\")\n",
        "start = time.time()\n",
        "for epoch in range(1, CFG[\"EPOCHS\"] + 1):\n",
        "    t0 = time.time()\n",
        "    tr_loss = train_one_epoch(epoch)\n",
        "    val_loss, val_acc, val_logloss = validate(epoch)\n",
        "    epoch_dur = time.time() - t0\n",
        "\n",
        "    logger.info(\n",
        "        f\"Epoch {epoch}/{CFG['EPOCHS']} | \"\n",
        "        f\"Time {epoch_dur:.1f}s | \"\n",
        "        f\"TrainLoss {tr_loss:.4f} | ValLoss {val_loss:.4f} | \"\n",
        "        f\"ValAcc {val_acc:.2f}% | LogLoss {val_logloss:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Save best by logloss\n",
        "    if val_logloss < BEST_LOSS:\n",
        "        BEST_LOSS = val_logloss\n",
        "        ckpt_path = PATHS[\"CKPT\"] / \"best_regnet_y_128gf_250612_b32.pth\"\n",
        "        torch.save(model.state_dict(), ckpt_path)\n",
        "        logger.info(f\"[Checkpoint] Saved at epoch {epoch} (LogLoss {BEST_LOSS:.4f})\")\n",
        "\n",
        "    early_stopper(val_logloss)\n",
        "    if early_stopper.stop:\n",
        "        logger.info(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "logger.info(f\"Total training time: {datetime.timedelta(seconds=int(time.time() - start))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Eval**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJJe3UnEgA6y"
      },
      "outputs": [],
      "source": [
        "# Inference\n",
        "weights = RegNet_Y_128GF_Weights.IMAGENET1K_SWAG_LINEAR_V1\n",
        "model   = regnet_y_128gf(weights=weights)\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, CFG['NUM_CLASSES'])\n",
        "\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, filenames in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        for prob in probs.cpu():\n",
        "            result = {\n",
        "                class_names[i]: prob[i].item()\n",
        "                for i in range(len(class_names))\n",
        "            }\n",
        "            results.append(result)\n",
        "            \n",
        "pred = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Submission\n",
        "submission = pd.read_csv(os.path.join(PATHS[\"SUBMIT\"], 'submission_JN.csv'), encoding='utf-8-sig')\n",
        "\n",
        "class_columns = submission.columns[1:]\n",
        "pred = pred[class_columns]\n",
        "\n",
        "submission[class_columns] = pred.values\n",
        "submission.to_csv(os.path.join(PATHS[\"SUBMIT\"], 'regnet_y_128gf_250612_b32_submission_JN.csv'), index=False, encoding='utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO3li9OAnGka1if4d+usg7h",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "1tXZe3gyQHzQnlNjadpS1QxSHl-_dRwZL",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "HAI_project",
      "language": "python",
      "name": "hai_project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
